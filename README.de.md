# Everlast Voice Intelligence

**KI-gest√ºtzte Sprache-zu-PowerPoint Desktop-Anwendung**

Eine Electron-basierte Desktop-Anwendung, die Sprachaufnahmen in professionelle PowerPoint-Pr√§sentationen umwandelt. Nutzt lokale LLMs f√ºr Transkription und Inhaltsaufbereitung.

---

## üöÄ Setup

### Abh√§ngigkeiten

#### Linux
```bash
# Node.js 18+ und Python 3.12+
sudo apt install nodejs npm python3 python3-pip python3-venv

# Projekt-Abh√§ngigkeiten installieren
npm install

# Whisper-Service einrichten (optional, f√ºr lokale Transkription)
cd services/whisper-service
./setup.sh
cd ../..
```

#### Windows
```bash
# Node.js 18+ installieren (von nodejs.org)
# Dann:
npm install

# Portable .exe verwenden (keine Python-Installation n√∂tig)
# Externe APIs f√ºr Whisper + LLM konfigurieren (siehe Einstellungen)
```

### Bibliotheken & Technologien

**Frontend**:
- Next.js 14.2 (React 18, App Router, statischer Export)
- Tailwind CSS (UI-Styling)
- Zustand (State Management)
- TypeScript (strenger Modus)

**Backend**:
- Electron 30 (Desktop-Framework)
- electron-store (persistente Einstellungen)
- node-record-lpcm16 (Audio-Aufnahme)

**AI/ML**:
- faster-whisper (lokale Transkription via Python)
- Ollama / Externe LLM API (llama3.1, Inhaltsverarbeitung)
- pptxgenjs (PowerPoint-Generierung)

**Python-Services** (optional):
- FastAPI (Whisper HTTP-Server)
- faster-whisper (GPU-beschleunigt mit CUDA)

---

## üèóÔ∏è Architektur

### Frontend-Komponenten (React/Next.js)

**Hauptansichten**:
- `RecordingControls` - Audio-Aufnahme/-Upload, Hotkey-Integration
- `TranscriptView` - Transkriptionsergebnisse mit Bearbeitung
- `AudioLibraryList` - Persistente Bibliothek f√ºr Audio + Transkripte
- `PresentationPreview` - Live-Vorschau mit Template-Wechsel
- `TemplateSelector` - 3 HTML-basierte Themes (Dark Yellow, Modern Blue, Organic Warm)
- `SettingsPanel` - Globale Einstellungen (LLM, Whisper, APIs, Hotkeys, Sprache)

**UI-Infrastruktur**:
- `ServiceStatus` - Echtzeit-Status√ºberwachung (Whisper/Ollama)
- `AIPipelineProgress` - 4-Stufen-Pipeline-Visualisierung
- `EditorToolbar` - Export-Funktionen (PPTX, Markdown)

**Workflow-Module**:
- `SaveToLibraryModal` - Speichern von Aufnahmen in Bibliothek
- `AudioDetailView` - Detailansicht mit Metadaten (Dauer, Name, Datum)
- `MarkdownViewModal` - Pr√§sentationszusammenfassungen als Markdown

### Backend-Architektur (Electron)

**Services** (`electron/services/`):
- `whisper-process.ts` - Whisper-Service-Management, externe API-Unterst√ºtzung
- `audio-recorder.ts` - Systemaufnahme √ºber node-record-lpcm16
- `settings-storage.ts` - Persistente Konfiguration via electron-store
- `hotkey-manager.ts` - Globale Tastenkombinationen (7 Voreinstellungen)

**IPC-Handler** (`electron/ipc-handlers.ts`):
- Audio-Transkription (lokal/extern)
- PPTX-Export mit Template-System
- Datei-I/O (Bibliothek als JSON)
- Service-Gesundheitspr√ºfungen

**Main Process** (`electron/main.ts`):
- Fenster-Management
- Nicht-blockierender Whisper-Start
- Globale Hotkey-Registrierung beim Start
- Cleanup alter Aufnahmen

### Datenfluss

```
[Aufnahme/Upload] 
    ‚Üì IPC
[Whisper Service] ‚Üí Transkript
    ‚Üì IPC
[Bibliothek speichern] ‚Üí JSON-Persistenz
    ‚Üì Benutzer w√§hlt aus
[AI-Pipeline (4 Stufen)]
    ‚îú‚îÄ Stufe 1: Paraphrase (Bereinigung)
    ‚îú‚îÄ Stufe 2: Segmentierung (Themen)
    ‚îú‚îÄ Stufe 3: Template-Auswahl (Slide-Typen)
    ‚îî‚îÄ Stufe 4: Content-Extraktion (Strukturierte Daten)
    ‚Üì
[PPTX-Renderer] ‚Üí Template anwenden
    ‚Üì
[Export] ‚Üí .pptx/.md Datei
```

**State Management**:
- Zustand Store (`recording-store.ts`) - Reaktiver globaler State
- Electron Store - Persistente Einstellungen
- JSON-Dateien - Bibliotheksdaten

**Cross-Platform**:
- Python-Startskript (`start.py`) - Windows/Linux-kompatibel
- Plattformerkennung f√ºr venv-Pfade (Scripts/ vs bin/)
- Externe API-Fallback f√ºr Windows (keine Python-Abh√§ngigkeit)

---

## üí° Konzepte & Entscheidungen

### AI-Pipeline-Architektur

**Problem**: Rohe Transkripte direkt in Slides zu konvertieren f√ºhrt zu inkoh√§renten, unstrukturierten Pr√§sentationen.

**L√∂sung**: 4-stufige Pipeline mit spezialisierten LLM-Prompts:

1. **Paraphrase** - Bereinigung von F√ºllw√∂rtern, Grammatikkorrektur, Strukturierung
2. **Segmentierung** - Thematische Aufteilung, Identifikation von Hauptpunkten
3. **Template-Selektion** - KI w√§hlt passende Slide-Typen (Titel, Aufz√§hlung, Tabelle, Flussdiagramm, 2-Spalten)
4. **Content-Extraktion** - Strukturierte Datenextraktion f√ºr jeden Slide-Typ

**Vorteil**: Jede Stufe hat einen klaren Fokus ‚Üí bessere Ergebnisse als Ein-Schritt-Ans√§tze.

### Rekursions-Layer f√ºr Geschwindigkeit

**Idee**: Optional aktivierbarer Verifikations-Layer (Stufe 5), der Ausgaben validiert und bei Bedarf neu generiert.

**Trade-off**: 
- ‚úÖ **Aus** (Standard): Schnelle Generierung (4 LLM-Aufrufe)
- ‚öôÔ∏è **An**: 2-3√ó langsamer, aber h√∂here Qualit√§t durch Selbstkorrektur

**Implementierung**: `verify-stage.ts` f√ºhrt Schema-Validierung durch und triggert Neuversuche bei Fehlern.

**Warum optional**: Die meisten Nutzer priorisieren Geschwindigkeit; Power-User k√∂nnen Qualit√§t aktivieren.

### Lokale LLMs f√ºr Datenschutz

**Transkription**: 
- faster-whisper (OpenAI's Whisper, lokal ausgef√ºhrt)
- Medium (1,5 GB) vs Large-v3 (10 GB) Modelle
- GPU-beschleunigt (CUDA 12) f√ºr Echtzeitverarbeitung

**Inhaltsaufbereitung**:
- Ollama (llama3.1:latest)
- Alle Prompts laufen lokal ‚Üí keine Cloud-Abh√§ngigkeit
- Quantisierung optional (Geschwindigkeit vs Genauigkeit)

**Externe API-Unterst√ºtzung**:
- Windows-Kompatibilit√§t (kein Python n√∂tig)
- Produktionsumgebungen ohne GPU
- OpenAI/Anthropic-kompatible Endpunkte

### Template-System f√ºr PPTX-Generierung

**Problem**: Programmatische PowerPoint-Erstellung erfordert manuelle Positionierung, Styling und Layout-Management.

**L√∂sung**: HTML-basierte Templates mit Slot-System:

```typescript
// Template definiert Farben, Schriften, Layout
const modernBlue = {
  primary: '#2563EB',    // Blau
  background: '#FFFFFF',
  text: '#1E293B',
  fonts: { heading: 'Montserrat', body: 'Open Sans' }
};

// Renderer f√ºllt Slots mit KI-extrahierten Daten
renderBulletSlide(content, modernBlue);
```

**3 Design-Themes**:
- **Dark Yellow** - Minimalistisch, hoher Kontrast (schwarz/gelb)
- **Modern Blue** - Professionell, kreisf√∂rmige Dekorelemente, nummerierte Listen
- **Organic Warm** - Beige/Orange, Eckenrahmen, Playfair Display-Schrift

**Vorteile**:
- KI muss nur Inhalte extrahieren, nicht designen
- Templates austauschbar ohne Logik-√Ñnderungen
- HTML-Prototypen ‚Üí 1:1 PPTX-√úbersetzung

### KI als Entwicklungsassistent

**Template-Generierung**:
- HTML-Prototypen mit GPT-4 erstellt
- Iteratives Refinement f√ºr Farben, Abst√§nde, Dekorationen
- TypeScript-Renderer aus HTML-Struktur generiert

**Debugging**:
- LLM-Prompt-Optimierung via Trial-and-Error mit KI-Feedback
- TypeScript-Fehleranalyse und L√∂sungsvorschl√§ge
- Refactoring-Unterst√ºtzung f√ºr Code-Qualit√§t

**Entwicklungs-Workflow**:
1. Konzept definieren (z.B. "moderne blaue Vorlage mit Kreisen")
2. KI generiert HTML + CSS-Prototyp
3. Manuelles Testen und Feedback
4. KI passt Code an ‚Üí Iteration bis perfekt
5. Conversion zu pptxgenjs-Renderer

**Ergebnis**: 3√ó schnellere Entwicklung bei konsistenter Code-Qualit√§t.

---

## üéØ Verwendung

### Schnellstart

```bash
# Entwicklungsmodus (Hot Reload)
npm run dev

# Produktions-Build
npm run build
npm start

# Windows Portable .exe erstellen
npm run package -- --win
```

### Workflow

1. **Aufnahme starten** - Hotkey (Standard: Ctrl+Shift+R) oder Upload
2. **Transkription** - Automatisch nach Aufnahmeende
3. **In Bibliothek speichern** - Namen vergeben, persistent speichern
4. **Pr√§sentation generieren** - Aufnahme w√§hlen ‚Üí Template w√§hlen ‚Üí Generieren
5. **Export** - Als .pptx oder .md exportieren

### Einstellungen

- **Hotkey**: 7 Voreinstellungen (F9-F11, Ctrl+Shift+R, etc.)
- **Whisper-Modell**: Medium (schnell) oder Large-v3 (genau)
- **LLM-Quantisierung**: Aktivieren f√ºr 2√ó Geschwindigkeit
- **Rekursions-Layer**: Aktivieren f√ºr h√∂here Qualit√§t
- **Externe APIs**: Whisper + LLM URLs/Keys konfigurieren
- **Sprache**: Deutsch/Englisch (Live-Wechsel)

---

## üì¶ Deployment

### Linux (Native)
```bash
# Alle Services lokal
npm run build && npm start
cd services/whisper-service && python3 start.py
# Ollama separat starten: ollama serve
```

### Windows (Portable)
```bash
# .exe aus release/ kopieren
# Keine Installation n√∂tig
# Externe APIs in Einstellungen konfigurieren:
#   - Whisper: https://api.openai.com/v1/audio/transcriptions
#   - LLM: https://api.openai.com/v1/chat/completions
```

---

## üîß Technische Details

**Zeilen Code**: ~5.078 LOC (TypeScript/Python)  
**Komponenten**: 21 React-Komponenten  
**Services**: 4 Electron-Services + 1 Python-Service  
**Abh√§ngigkeiten**: 23 npm-Pakete  
**Build-Gr√∂√üe**: 128 MB (Windows .exe)  

**Code-Qualit√§t**:
- TypeScript strict mode ‚úÖ
- ESLint passing ‚úÖ
- Zero TODO/FIXME ‚úÖ
- Cross-platform kompatibel ‚úÖ

---

## üìÑ Lizenz

MIT License - siehe LICENSE-Datei f√ºr Details.

---

## üôè Danksagungen

Entwickelt mit Unterst√ºtzung von KI-Tools (GPT-4, Claude) f√ºr:
- Template-Design und HTML/CSS-Generierung
- TypeScript-Refactoring und Fehleranalyse
- LLM-Prompt-Engineering und Optimierung
- Architekturentscheidungen und Best Practices

**Kernideen**: Mehrstufige AI-Pipeline, lokale LLM-Integration, HTML-Template-System - alle von Menschen konzipiert und implementiert, KI-unterst√ºtzt verfeinert.
